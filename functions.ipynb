{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get text completetion from gpt api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo-1106\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model, messages=messages, temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to iterate through multiple PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get a specific year's PDFs\n",
    "# assign directory\n",
    "# directory = \"/Users/st414/Documents/PLR/sample_plrs\"\n",
    "\n",
    "\n",
    "# iterate over files in that directory\n",
    "def files_by_year(year, folder_path):\n",
    "    plr_list_by_year = []\n",
    "    files = os.listdir(folder_path)\n",
    "    for file in files:\n",
    "        # print(file)\n",
    "        if len(file) == 11:\n",
    "            if str(year)[-2:] == str(file)[0:2]:\n",
    "                plr_list_by_year.append(file)\n",
    "        if len(file) == 13 and \"_\" in file:\n",
    "            if str(year)[-2:] == str(file)[0:2]:\n",
    "                plr_list_by_year.append(file)\n",
    "        if len(file) == 13:\n",
    "            if str(year) == str(file)[0:4]:\n",
    "                plr_list_by_year.append(file)\n",
    "        if len(file) == 15 and \"_\" in file:\n",
    "            if str(year) == str(file)[0:4]:\n",
    "                plr_list_by_year.append(file)\n",
    "    # print(file_list_by_year)\n",
    "    return plr_list_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to iterate through multiple PLRs and get classification\n",
    "# encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo-1106\")\n",
    "\n",
    "def get_plr_classification(year, folder_path):\n",
    "    plr_classification_list = []\n",
    "    plr_list_by_year = files_by_year(year, folder_path)\n",
    "    for plr in plr_list_by_year:\n",
    "        plr_classification_dict = {}\n",
    "        plr_filepath = os.path.join(folder_path, plr)\n",
    "        pdf_to_convert = fitz.open(plr_filepath)\n",
    "        plr_text = \"\"\n",
    "        for page in pdf_to_convert:\n",
    "            text = page.get_text()\n",
    "            plr_text += text\n",
    "        # get classification\n",
    "        if len(encoding.encode(plr_text)) > 13000:\n",
    "            pass\n",
    "        else:\n",
    "            print(plr)\n",
    "            prompt = f\"\"\"\n",
    "        Your task is to classify letter rulings as adverse or non-adverse by using\n",
    "        knowledge and context from the literature provided to you below, delimited\n",
    "        by triple dollar signs.\n",
    "\n",
    "        Literature: $$${letterRuling_context}$$$\n",
    "\n",
    "        Below is the letter ruling, delimited by triple backticks, which has to be classified as Adverse or Non Adverse.\n",
    "\n",
    "        Letter Ruling: ```{plr_text}```\n",
    "\n",
    "        Provide your output as one of the two values: Adverse or Non-Adverse.\n",
    "        \"\"\"\n",
    "\n",
    "        response = get_completion(prompt)\n",
    "        plr_classification_dict = {int(plr.split(\".\")[0]): response}\n",
    "        plr_classification_list.append(plr_classification_dict)\n",
    "    return plr_classification_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate accuracy, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_df(list_of_dicts):\n",
    "    keys = []\n",
    "    values = []\n",
    "\n",
    "    for dict in list_of_dicts:\n",
    "        for key, value in dict.items():\n",
    "            keys.append(key)\n",
    "            values.append(value)\n",
    "    # create a dataframe\n",
    "    df = pd.DataFrame({'plr_number': keys, 'tag': values})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(list_of_dicts, reference_set):\n",
    "    # Convert list of dicts to DataFrame\n",
    "    list_df = list_to_df(list_of_dicts)\n",
    "\n",
    "    # Merge the DataFrame and list_df based on the PLR number\n",
    "    merged_df = pd.merge(reference_set, list_df, on='plr_number', suffixes=('_ref', '_list'))\n",
    "    #print(merged_df.loc[(merged_df['tag_ref'] == 'Adverse') & (merged_df['tag_list'] == 'Non-Adverse')])\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = sum(merged_df['tag_ref'] == merged_df['tag_list']) / len(merged_df)\n",
    "\n",
    "    # Calculate recall\n",
    "    true_positives = sum((merged_df['tag_ref'] == 'Adverse') & (merged_df['tag_list'] == 'Adverse'))\n",
    "    false_negatives = sum((merged_df['tag_ref'] == 'Adverse') & (merged_df['tag_list'] != 'Adverse'))\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "\n",
    "    # Calculate precision\n",
    "    false_positives = sum((merged_df['tag_ref'] != 'Adverse') & (merged_df['tag_list'] == 'Adverse'))\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "    print(f\"Recall: {recall*100:.2f}%\")\n",
    "    print(f\"Precision: {precision*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through multiple years\n",
    "def iterate_multiple_years(years, folder_path):\n",
    "    years_list = []\n",
    "    for y in years:\n",
    "        years_list.extend(get_plr_classification(y, folder_path))\n",
    "    return years_list\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert a list of dict items to pandas dataframe and write to output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_excel(list, output_folder_path, output_filename):\n",
    "    # Create a DataFrame from the list using list comprehension\n",
    "    df = pd.DataFrame([(key, value) for item in list for key, value in item.items()], columns=['PLR Number', 'Classification'])\n",
    "    \n",
    "    # Write the DataFrame to the Excel file\n",
    "    df.to_csv(output_folder_path+'/'+output_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tuning funcions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text from pdf\n",
    "\n",
    "def extract_pdf_text(pdf_file):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF file.\n",
    "    Args:\n",
    "        pdf_file: Path to the PDF file.\n",
    "    Returns:\n",
    "        Extracted text as a string.\n",
    "    \"\"\"\n",
    "    pdf_to_convert = fitz.open(pdf_file)\n",
    "    plr_text = \"\"\n",
    "    for page in pdf_to_convert:\n",
    "        text = page.get_text()\n",
    "        plr_text += text\n",
    "    return plr_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make pandas dataframe for plrs\n",
    "\n",
    "def text_to_df():\n",
    "  # Replace with the actual directory containing your PDFs\n",
    "  pdf_folder = train_folder\n",
    "\n",
    "  # Create an empty list to store data\n",
    "  data = []\n",
    "\n",
    "  # Iterate through all PDF files in the folder\n",
    "  for filename in os.listdir(pdf_folder):\n",
    "    if filename.endswith(\".pdf\"):  # Check for PDF extension\n",
    "      pdf_path = os.path.join(pdf_folder, filename)\n",
    "      extracted_text = extract_pdf_text(pdf_path)\n",
    "      data.append({\"plr_number\": filename, \"text\": extracted_text})\n",
    "\n",
    "  # Create DataFrame from list\n",
    "  df = pd.DataFrame(data)\n",
    "\n",
    "  return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
